{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check paths below...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "\n",
    "sys.path.append(\"/home/sebastian/Udacity/SDC-System-Integration/classifier/models\") # point to your tensorflow dir\n",
    "sys.path.append(\"/home/sebastian/Udacity/SDC-System-Integration/classifier/models/slim\")\n",
    "sys.path.append(\"/home/sebastian/Udacity/SDC-System-Integration/classifier/models/object_detection/\")\n",
    "\n",
    "# data directory containing rgb folder and train.yaml\n",
    "PATH_TO_DATA = '/home/sebastian/Udacity/SDC-System-Integration/classifier/data' \n",
    "TF_RECORD_TRAIN_PATH =PATH_TO_DATA+'/train.record'\n",
    "TF_RECORD_TEST_PATH =PATH_TO_DATA+'/test.record'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict =  {\n",
    "   \"Green\" : 1,\n",
    "   \"Red\" : 2,\n",
    "   \"GreenLeft\" : 3,\n",
    "   \"GreenRight\" : 4,\n",
    "   \"RedLeft\" : 5,\n",
    "   \"RedRight\" : 6,\n",
    "   \"Yellow\" : 7,\n",
    "   \"off\" : 8,\n",
    "   \"RedStraight\" : 9,\n",
    "   \"GreenStraight\" : 10,\n",
    "   \"GreenStraightLeft\" : 11,\n",
    "   \"GreenStraightRight\" : 12,\n",
    "   \"RedStraightLeft\" : 13,\n",
    "   \"RedStraightRight\" : 14\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util\n",
    "\n",
    "def get_all_labels(input_yaml, riib=False):\n",
    "    \"\"\" Gets all labels within label file\n",
    "    Note that RGB images are 1280x720 and RIIB images are 1280x736.\n",
    "    :param input_yaml: Path to yaml file\n",
    "    :param riib: If True, change path to labeled pictures\n",
    "    :return: images: Labels for traffic lights\n",
    "    \"\"\"\n",
    "    images = yaml.load(open(input_yaml, 'rb').read())\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        images[i]['path'] = os.path.abspath(os.path.join(os.path.dirname(input_yaml), images[i]['path']))\n",
    "        if riib:\n",
    "            images[i]['path'] = images[i]['path'].replace('.png', '.pgm')\n",
    "            images[i]['path'] = images[i]['path'].replace('rgb/train', 'riib/train')\n",
    "            images[i]['path'] = images[i]['path'].replace('rgb/test', 'riib/test')\n",
    "            for box in images[i]['boxes']:\n",
    "                box['y_max'] = box['y_max'] + 8\n",
    "                box['y_min'] = box['y_min'] + 8\n",
    "    return images\n",
    "\n",
    "def create_tf_example(example):\n",
    "    # TODO(user): Populate the following variables from your example.\n",
    "    height = 720 # Image height\n",
    "    width = 1280 # Image width\n",
    "    filepath = example['path'] \n",
    "\n",
    "    filename = filepath.split('/').pop() # Filename of the image. Empty if image is not from file\n",
    "\n",
    "    with tf.gfile.GFile(filepath, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "\n",
    "    key = hashlib.sha256(encoded_image_data).hexdigest()\n",
    "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = [] # List of integer class id of bounding box (1 per box)\n",
    "    \n",
    "    for box in example['boxes']:\n",
    "        if box['occluded']:\n",
    "            continue\n",
    "        else:\n",
    "            xmins.append(box['x_min']/width)\n",
    "            xmaxs.append(box['x_max']/width)\n",
    "            ymins.append(box['y_min']/height)\n",
    "            ymaxs.append(box['y_max']/height)\n",
    "            classes_text.append(box['label'])\n",
    "            classes.append(label_dict.get(box['label']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature('png'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = get_all_labels(PATH_TO_DATA + '/train.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = get_all_labels(PATH_TO_DATA + '/test.yaml')\n",
    "# fix for test dataset\n",
    "for data in dataset_test:\n",
    "    data['path'] = PATH_TO_DATA+'/rgb/test/'+data['path'].split('/').pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write one big file ..around 7GB\n",
    "\n",
    "writer_train = tf.python_io.TFRecordWriter(TF_RECORD_TRAIN_PATH)\n",
    "for example in dataset_train:\n",
    "    train = create_tf_example(example)\n",
    "    writer_train.write(train.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_test = tf.python_io.TFRecordWriter(TF_RECORD_TEST_PATH)\n",
    "for example in dataset_test:\n",
    "    test = create_tf_example(example)\n",
    "    writer_test.write(test.SerializeToString())\n",
    "writer_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'207374.png'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]['path'].split('/').pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = create_tf_example(dataset_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.gfile.GFile(dataset_train[100]['path'], 'rb') as fid:\n",
    "    encoded_image_data = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\x00\\x00\\x00\\x02\\xd0\\x08\\x02\\x00\\x00\\x00@\\x1fJ\\x01\\x00\\x00 \\x00IDATx\\x01\\x00\\x8fBp\\xbd\\x01o|g\\xff\\x06\\xfc\\xfa\\x06\\xfa\\xfc\\xf8\\x08\\x07\\xfc\\x06\\x03\\x06\\xf8\\xf9\\x02\\xfc\\xf8\\xf4\\xf6\\xf1\\xf4\\xf6\\xf2\\xee\\xfc\\xfb\\xf8\\xf0\\xfe\\xfc\\x00\\t\\xfc\\x02\\n\\x07\\x07\\xfa\\x13\\xf0\\x00\\xf7\\x13\\x06\\x07\\xfe'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_image_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'png'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = 'png'\n",
    "strings.encode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
